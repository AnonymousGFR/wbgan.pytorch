CelebaHQ1024:
  loader:
    dataset: CelebaHQ1024
    datadir: ~/.keras/celeba1024/
    batch_size: 128
    shuffle: false
    num_workers: 6
    seed: 0
  saved_inception_moments: '~/.keras/BigGAN-PyTorch-1/CelebaHQ1024_inception_moments.npz'
  parallel: true
  augment: false

CelebaHQ128:
  loader:
    dataset: CelebaHQ128
    datadir: ~/.keras/celeba128/
    batch_size: 64
    shuffle: false
    num_workers: 2
    seed: 0
  saved_inception_moments: '~/.keras/BigGAN-PyTorch-1/CelebaHQ128_inception_moments.npz'
  parallel: true
  augment: false


wgan_gp_celebaHQ1024:
  seed: 1234
  model:
    parallel: true
    ema_start: 5000
    Generator:
      G_ch: 32
      dim_z: 120
      bottom_width: 4
      G_kernel_size: 3
      G_attn: '0'
      G_shared: true
      shared_dim: 128
      hier: true
      cross_replica: false
      mybn: false
      G_activation: inplace_relu
      G_init: ortho
      G_param: SN
      norm_style: bn
      BN_eps: 0.00001
      SN_eps: 0.000001
      G_fp16: false
      num_G_SVs: 1
      num_G_SV_itrs: 1
      G_mixed_precision: false
    Discriminator:
      D_ch: 32
      D_wide: true
      D_kernel_size: 3
      D_attn: '0'
      D_activation: inplace_relu
      D_init: ortho
      D_param: SN
      SN_eps: 0.000001
      D_fp16: false
      num_D_SVs: 1
      num_D_SV_itrs: 1
      D_mixed_precision: false
  optimizer:
    G_lr: 0.0001
    G_B1: 0.
    G_B2: 0.999
    D_lr: 0.0001
    D_B1: 0.
    D_B2: 0.999
    adam_eps: 0.000001
  noise:
    batch_size: 64
    G_batch_size: 0
    z_mean: 0.
    z_var: 1.
  inception_metric:
    saved_inception_moments: ../results/datasets/CelebaHQ_128_inception_moments.npz
    num_inception_images: 30000
  dataset:
    dataset: CelebaHQ_128
    data_root: ~/.keras/celeba128
    load_in_mem: true
    augment: false
    use_multiepoch_sampler: false
    num_workers: 2
    pin_memory: false
    drop_last: true
    shuffle: true
  loader:
    dataset: CelebaHQ1024
    datadir: ~/.keras/celeba1024/
    batch_size: 128
    shuffle: false
    num_workers: 6
    seed: 0
  train:
    epochs: 200
  train_one_epoch:
    dummy_train: false
    toggle_grads: true
    num_D_steps: 1
    num_D_accumulations: 1
    split_D: false
    gp_lambda: 10.
    D_ortho: 0.0
    G_ortho: 0.0
    num_G_accumulations: 1
    sample_every: 100
    sample_start_iter: 20000
  summary_images:
    bs_log: 64
    n_row: 8
  test:
    use_ema: false
    sample_interpolation:
      classes_per_sheet: 1
      num_per_sheet: 16
      num_midpoints: 8


celebahq128_wgan_gp:
  seed: 1234
  epochs: 200
  model:
    z_dim: 100
    ema_start: 5000
    parallel: false
    Generator:
      G_ch: 32
#      G_ch: 32
      dim_z: 120
      bottom_width: 4
      G_kernel_size: 3
      G_attn: '0'
      G_shared: true
      shared_dim: 128
      hier: true
      cross_replica: false
      mybn: false
      G_activation: inplace_relu
      G_init: ortho
      G_param: SN
      norm_style: bn
      BN_eps: 0.00001
      SN_eps: 0.000001
      G_fp16: false
      num_G_SVs: 1
      num_G_SV_itrs: 1
      G_mixed_precision: false
    Discriminator:
      D_ch: 32
#      D_ch: 32
      D_wide: true
      D_kernel_size: 3
      D_attn: '0'
      D_activation: inplace_relu
      D_init: ortho
      D_param: SN
      SN_eps: 0.000001
      D_fp16: false
      num_D_SVs: 1
      num_D_SV_itrs: 1
      D_mixed_precision: false
    optimizer:
      G_lr: 0.0001
      G_B1: 0.
      G_B2: 0.999
      D_lr: 0.0001
      D_B1: 0.
      D_B2: 0.999
      adam_eps: 0.000001
  noise:
    batch_size: 64
    G_batch_size: 0
    z_mean: 0.
    z_var: 1.
  inception_metric:
    saved_inception_moments: '~/.keras/BigGAN-PyTorch-1/CelebaHQ128_inception_moments.npz'
    num_inception_images: 30000
  dataset:
    dataset: 'celebahq128'
    data_root: ~/.keras/celeba128
    index_filename: '~/.keras/BigGAN-PyTorch-1/celeba128_index.npz'
    load_in_mem: false
#    load_in_mem: true
    augment: false
    use_multiepoch_sampler: false
    num_workers: 2
    pin_memory: false
    drop_last: true
    shuffle: true

  train_one_epoch:
    dummy_train: false
    toggle_grads: true
    num_D_steps: 1
    num_D_accumulations: 1
    split_D: false
    adaptive_gp: false
    adv_train: false
    gp_lambda: 10.
    use_bound: false
    D_ortho: 0.0
    G_ortho: 0.0
    num_G_accumulations: 1
    sample_every: 100
    sample_start_iter: 20000
  summary_images:
    bs_log: 64
    n_row: 8
  test:
    use_ema: false


celebahq128_wgan_gpreal:
  seed: 1234
  epochs: 200
  model:
    z_dim: 100
    ema_start: 5000
    parallel: false
    Generator:
      G_ch: 32
#      G_ch: 32
      dim_z: 120
      bottom_width: 4
      G_kernel_size: 3
      G_attn: '0'
      G_shared: true
      shared_dim: 128
      hier: true
      cross_replica: false
      mybn: false
      G_activation: inplace_relu
      G_init: ortho
      G_param: SN
      norm_style: bn
      BN_eps: 0.00001
      SN_eps: 0.000001
      G_fp16: false
      num_G_SVs: 1
      num_G_SV_itrs: 1
      G_mixed_precision: false
    Discriminator:
      D_ch: 32
#      D_ch: 32
      D_wide: true
      D_kernel_size: 3
      D_attn: '0'
      D_activation: inplace_relu
      D_init: ortho
      D_param: SN
      SN_eps: 0.000001
      D_fp16: false
      num_D_SVs: 1
      num_D_SV_itrs: 1
      D_mixed_precision: false
    optimizer:
#      type:
      type: radam
      G_lr: 0.0001
      G_B1: 0.
      G_B2: 0.999
      D_lr: 0.0001
      D_B1: 0.
      D_B2: 0.999
      adam_eps: 0.000001
  noise:
    batch_size: 64
    G_batch_size: 0
    z_mean: 0.
    z_var: 1.
  inception_metric:
    saved_inception_moments: '~/.keras/BigGAN-PyTorch-1/CelebaHQ128_inception_moments.npz'
    num_inception_images: 30000
  dataset:
    dataset: 'celebahq128'
    data_root: ~/.keras/celeba128
    index_filename: '~/.keras/BigGAN-PyTorch-1/celeba128_index.npz'
    load_in_mem: false
#    load_in_mem: true
    augment: false
    use_multiepoch_sampler: false
    num_workers: 2
    pin_memory: false
    drop_last: true
    shuffle: true

  train_one_epoch:
    dummy_train: false
    toggle_grads: true
    num_D_steps: 1
    num_D_accumulations: 1
    split_D: false
    adaptive_gp: false
    gp_value:
    gp_lambda: 10.
    adv_train: false
    adv_epoch:
    adv_lr: 0.1
    adv_value: 0
    adv_lambda: 0.001
    use_bound: false
    bound: 3
    D_ortho: 0.0
    G_ortho: 0.0
    num_G_accumulations: 1
    sample_every: 100
    sample_start_iter: 20000
  summary_images:
    bs_log: 64
    n_row: 8
  test:
    use_ema: false


celebahq128_wgan_gpreal_bound:
  seed: 1234
  epochs: 200
  model:
    z_dim: 100
    ema_start: 5000
    parallel: false
    Generator:
      G_ch: 32
#      G_ch: 32
      dim_z: 120
      bottom_width: 4
      G_kernel_size: 3
      G_attn: '0'
      G_shared: true
      shared_dim: 128
      hier: true
      cross_replica: false
      mybn: false
      G_activation: inplace_relu
      G_init: ortho
      G_param: SN
      norm_style: bn
      BN_eps: 0.00001
      SN_eps: 0.000001
      G_fp16: false
      num_G_SVs: 1
      num_G_SV_itrs: 1
      G_mixed_precision: false
    Discriminator:
      D_ch: 32
#      D_ch: 32
      D_wide: true
      D_kernel_size: 3
      D_attn: '0'
      D_activation: inplace_relu
      D_init: ortho
      D_param: SN
      SN_eps: 0.000001
      D_fp16: false
      num_D_SVs: 1
      num_D_SV_itrs: 1
      D_mixed_precision: false
    optimizer:
      G_lr: 0.0001
      G_B1: 0.
      G_B2: 0.999
      D_lr: 0.0001
      D_B1: 0.
      D_B2: 0.999
      adam_eps: 0.000001
  noise:
    batch_size: 64
    G_batch_size: 0
    z_mean: 0.
    z_var: 1.
  inception_metric:
    saved_inception_moments: '~/.keras/BigGAN-PyTorch-1/CelebaHQ128_inception_moments.npz'
    num_inception_images: 30000
  dataset:
    dataset: 'celebahq128'
    data_root: ~/.keras/celeba128
    index_filename: '~/.keras/BigGAN-PyTorch-1/celeba128_index.npz'
    load_in_mem: false
#    load_in_mem: true
    augment: false
    use_multiepoch_sampler: false
    num_workers: 2
    pin_memory: false
    drop_last: true
    shuffle: true

  train_one_epoch:
    dummy_train: false
    toggle_grads: true
    num_D_steps: 1
    num_D_accumulations: 1
    split_D: false
    adaptive_gp: false
    gp_value:
    adv_train: false
    adv_lr: 0.1
    adv_value: 0
    adv_lambda: 0.001
    gp_lambda: 10.
    use_bound: true
    bound: 3
    D_ortho: 0.0
    G_ortho: 0.0
    num_G_accumulations: 1
    sample_every: 100
    sample_start_iter: 20000
  summary_images:
    bs_log: 64
    n_row: 8
  test:
    use_ema: false


celebahq128_wgan_gpreal_adv:
  seed: 1234
  epochs: 200
  model:
    z_dim: 100
    ema_start: 5000
    parallel: false
    Generator:
      G_ch: 32
#      G_ch: 32
      dim_z: 120
      bottom_width: 4
      G_kernel_size: 3
      G_attn: '0'
      G_shared: true
      shared_dim: 128
      hier: true
      cross_replica: false
      mybn: false
      G_activation: inplace_relu
      G_init: ortho
      G_param: SN
      norm_style: bn
      BN_eps: 0.00001
      SN_eps: 0.000001
      G_fp16: false
      num_G_SVs: 1
      num_G_SV_itrs: 1
      G_mixed_precision: false
    Discriminator:
      D_ch: 32
#      D_ch: 32
      D_wide: true
      D_kernel_size: 3
      D_attn: '0'
      D_activation: inplace_relu
      D_init: ortho
      D_param: SN
      SN_eps: 0.000001
      D_fp16: false
      num_D_SVs: 1
      num_D_SV_itrs: 1
      D_mixed_precision: false
    optimizer:
#      type: radam
      G_lr: 0.0001
      G_B1: 0.
      G_B2: 0.999
      D_lr: 0.0001
      D_B1: 0.
      D_B2: 0.999
      adam_eps: 0.000001
  noise:
    batch_size: 64
    G_batch_size: 0
    z_mean: 0.
    z_var: 1.
  inception_metric:
    saved_inception_moments: '~/.keras/BigGAN-PyTorch-1/CelebaHQ128_inception_moments.npz'
    num_inception_images: 30000
  dataset:
    dataset: 'celebahq128'
    data_root: ~/.keras/celeba128
    index_filename: '~/.keras/BigGAN-PyTorch-1/celeba128_index.npz'
    load_in_mem: false
#    load_in_mem: true
    augment: false
    use_multiepoch_sampler: false
    num_workers: 2
    pin_memory: false
    drop_last: true
    shuffle: true

  train_one_epoch:
    dummy_train: false
    toggle_grads: true
    num_D_steps: 1
    num_D_accumulations: 1
    split_D: false
    adaptive_gp: false
    gp_value:
    gp_lambda: 10.
    adv_train: true
    adv_epoch: 1
    adv_lr: 0.1
    adv_value: 0
    adv_lambda: 0.1
    use_bound: false
    D_ortho: 0.0
    G_ortho: 0.0
    num_G_accumulations: 1
    sample_every: 100
    sample_start_iter: 20000
  summary_images:
    bs_log: 64
    n_row: 8
  test:
    use_ema: false


celebahq1024_wgan_gp:
  seed: 1234
  epochs: 200
  model:
    z_dim: 100
    ema_start: 5000
    parallel: true
    Generator:
      G_ch: 32
#      G_ch: 32
      dim_z: 120
      bottom_width: 4
      G_kernel_size: 3
      G_attn: '0'
      G_shared: true
      shared_dim: 128
      hier: true
      cross_replica: false
      mybn: false
      G_activation: inplace_relu
      G_init: ortho
      G_param: SN
      norm_style: bn
      BN_eps: 0.00001
      SN_eps: 0.000001
      G_fp16: false
      num_G_SVs: 1
      num_G_SV_itrs: 1
      G_mixed_precision: false
    Discriminator:
      D_ch: 32
#      D_ch: 32
      D_wide: true
      D_kernel_size: 3
      D_attn: '0'
      D_activation: inplace_relu
      D_init: ortho
      D_param: SN
      SN_eps: 0.000001
      D_fp16: false
      num_D_SVs: 1
      num_D_SV_itrs: 1
      D_mixed_precision: false
    optimizer:
      G_lr: 0.0001
      G_B1: 0.
      G_B2: 0.999
      D_lr: 0.0001
      D_B1: 0.
      D_B2: 0.999
      adam_eps: 0.000001
  noise:
    batch_size: 2
#    batch_size: 48
    G_batch_size: 0
    z_mean: 0.
    z_var: 1.
  inception_metric:
    saved_inception_moments: '~/.keras/BigGAN-PyTorch-1/CelebaHQ1024_inception_moments.npz'
    num_inception_images: 30000
  dataset:
    dataset: 'celebahq1024'
    data_root: ~/.keras/celeba1024
    index_filename: '~/.keras/BigGAN-PyTorch-1/celeba1024_index.npz'
    load_in_mem: false
#    load_in_mem: true
    augment: false
    use_multiepoch_sampler: false
    num_workers: 2
    pin_memory: false
    drop_last: true
    shuffle: true

  train_one_epoch:
    dummy_train: false
    toggle_grads: true
    num_D_steps: 1
    num_D_accumulations: 1
    split_D: false
    adaptive_gp: false
    adv_train: false
    gp_lambda: 10.
    use_bound: false
    D_ortho: 0.0
    G_ortho: 0.0
    num_G_accumulations: 1
    sample_every: 100
    sample_start_iter: 20000
  summary_images:
    bs_log: 64
    n_row: 8
  test:
    use_ema: false


celebahq1024_wgan_gpreal:
  seed: 1234
  epochs: 200
  model:
    z_dim: 100
    ema_start: 5000
    parallel: true
    Generator:
      G_ch: 32
#      G_ch: 32
      dim_z: 120
      bottom_width: 4
      G_kernel_size: 3
      G_attn: '0'
      G_shared: true
      shared_dim: 128
      hier: true
      cross_replica: false
      mybn: false
      G_activation: inplace_relu
      G_init: ortho
      G_param: SN
      norm_style: bn
      BN_eps: 0.00001
      SN_eps: 0.000001
      G_fp16: false
      num_G_SVs: 1
      num_G_SV_itrs: 1
      G_mixed_precision: false
    Discriminator:
      D_ch: 32
#      D_ch: 32
      D_wide: true
      D_kernel_size: 3
      D_attn: '0'
      D_activation: inplace_relu
      D_init: ortho
      D_param: SN
      SN_eps: 0.000001
      D_fp16: false
      num_D_SVs: 1
      num_D_SV_itrs: 1
      D_mixed_precision: false
    optimizer:
      G_lr: 0.0001
      G_B1: 0.
      G_B2: 0.999
      D_lr: 0.0001
      D_B1: 0.
      D_B2: 0.999
      adam_eps: 0.000001
  noise:
    batch_size: 2
#    batch_size: 48
    G_batch_size: 0
    z_mean: 0.
    z_var: 1.
  inception_metric:
    saved_inception_moments: '~/.keras/BigGAN-PyTorch-1/CelebaHQ1024_inception_moments.npz'
    num_inception_images: 30000
  dataset:
    dataset: 'celebahq1024'
    data_root: ~/.keras/celeba1024
    index_filename: '~/.keras/BigGAN-PyTorch-1/celeba1024_index.npz'
    load_in_mem: false
#    load_in_mem: true
    augment: false
    use_multiepoch_sampler: false
    num_workers: 2
    pin_memory: false
    drop_last: true
    shuffle: true

  train_one_epoch:
    dummy_train: false
    toggle_grads: true
    num_D_steps: 1
    num_D_accumulations: 1
    split_D: false
    adaptive_gp: false
    adv_train: false
    gp_lambda: 10.
    use_bound: false
    D_ortho: 0.0
    G_ortho: 0.0
    num_G_accumulations: 1
    sample_every: 100
    sample_start_iter: 20000
  summary_images:
    bs_log: 64
    n_row: 8
  test:
    use_ema: false


celebahq1024_wgan_gpreal_adv:
  seed: 1234
  epochs: 200
  model:
    z_dim: 100
    ema_start: 5000
    parallel: true
    Generator:
      G_ch: 32
#      G_ch: 32
      dim_z: 120
      bottom_width: 4
      G_kernel_size: 3
      G_attn: '0'
      G_shared: true
      shared_dim: 128
      hier: true
      cross_replica: false
      mybn: false
      G_activation: inplace_relu
      G_init: ortho
      G_param: SN
      norm_style: bn
      BN_eps: 0.00001
      SN_eps: 0.000001
      G_fp16: false
      num_G_SVs: 1
      num_G_SV_itrs: 1
      G_mixed_precision: false
    Discriminator:
      D_ch: 32
#      D_ch: 32
      D_wide: true
      D_kernel_size: 3
      D_attn: '0'
      D_activation: inplace_relu
      D_init: ortho
      D_param: SN
      SN_eps: 0.000001
      D_fp16: false
      num_D_SVs: 1
      num_D_SV_itrs: 1
      D_mixed_precision: false
    optimizer:
      G_lr: 0.0001
      G_B1: 0.
      G_B2: 0.999
      D_lr: 0.0001
      D_B1: 0.
      D_B2: 0.999
      adam_eps: 0.000001
  noise:
    batch_size: 2
#    batch_size: 48
    G_batch_size: 0
    z_mean: 0.
    z_var: 1.
  inception_metric:
    saved_inception_moments: '~/.keras/BigGAN-PyTorch-1/CelebaHQ1024_inception_moments.npz'
    num_inception_images: 30000
  dataset:
    dataset: 'celebahq1024'
    data_root: ~/.keras/celeba1024
    index_filename: '~/.keras/BigGAN-PyTorch-1/celeba1024_index.npz'
    load_in_mem: false
#    load_in_mem: true
    augment: false
    use_multiepoch_sampler: false
    num_workers: 2
    pin_memory: false
    drop_last: true
    shuffle: true

  train_one_epoch:
    dummy_train: false
    toggle_grads: true
    num_D_steps: 1
    num_D_accumulations: 1
    split_D: false
    adaptive_gp: false
    adv_train: true
    adv_lr: 0.1
    adv_value: 0
    adv_lambda: 0.001
    gp_lambda: 10.
    use_bound: false
    D_ortho: 0.0
    G_ortho: 0.0
    num_G_accumulations: 1
    sample_every: 100
    sample_start_iter: 20000
  summary_images:
    bs_log: 64
    n_row: 8
  test:
    use_ema: false